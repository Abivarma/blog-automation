{
  "date": "2026-02-26",
  "primary": {
    "title": "Never buy a .online domain",
    "url": "https://www.0xsid.com/blog/online-tld-is-pain",
    "source": "hackernews",
    "summary": "Never buy a .online domain",
    "engagement_score": 0.6702,
    "published_at": "2026-02-25T13:31:17+00:00",
    "keywords": [],
    "raw_data": {
      "hn_id": 47151233,
      "comments": 419
    }
  },
  "backups": [
    {
      "title": "Recovered in Translation: Efficient Pipeline for Automated Translation of Benchmarks and Datasets",
      "url": "https://arxiv.org/abs/2602.22207v1",
      "source": "arxiv",
      "summary": "The reliability of multilingual Large Language Model (LLM) evaluation is currently compromised by the inconsistent quality of translated benchmarks. Existing resources often suffer from semantic drift and context loss, which can lead to misleading performance metrics. In this work, we present a fully automated framework designed to address these challenges by enabling scalable, high-quality translation of datasets and benchmarks. We demonstrate that adapting test-time compute scaling strategies,",
      "engagement_score": 0.6579,
      "published_at": "2026-02-25T18:58:25Z",
      "keywords": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "raw_data": {}
    },
    {
      "title": "GUI-Libra: Training Native GUI Agents to Reason and Act with Action-aware Supervision and Partially Verifiable RL",
      "url": "https://arxiv.org/abs/2602.22190v1",
      "source": "arxiv",
      "summary": "Open-source native GUI agents still lag behind closed-source systems on long-horizon navigation tasks. This gap stems from two limitations: a shortage of high-quality, action-aligned reasoning data, and the direct adoption of generic post-training pipelines that overlook the unique challenges of GUI agents. We identify two fundamental issues in these pipelines: (i) standard SFT with CoT reasoning often hurts grounding, and (ii) step-wise RLVR-tyle training faces partial verifiability, where mult",
      "engagement_score": 0.6563,
      "published_at": "2026-02-25T18:34:57Z",
      "keywords": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "raw_data": {}
    },
    {
      "title": "Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual",
      "url": "https://arxiv.org/abs/2602.22146v1",
      "source": "arxiv",
      "summary": "Reinforcement Learning from Human Feedback (RLHF) plays a significant role in aligning Large Language Models (LLMs) with human preferences. While RLHF with expected reward constraints can be formulated as a primal-dual optimization problem, standard primal-dual methods only guarantee convergence with a distributional policy where the saddle-point problem is in convex-concave form. Moreover, standard primal-dual methods may exhibit instability or divergence in the last iterate under policy parame",
      "engagement_score": 0.6535,
      "published_at": "2026-02-25T17:54:52Z",
      "keywords": [
        "cs.LG",
        "cs.AI"
      ],
      "raw_data": {}
    },
    {
      "title": "SigmaQuant: Hardware-Aware Heterogeneous Quantization Method for Edge DNN Inference",
      "url": "https://arxiv.org/abs/2602.22136v1",
      "source": "arxiv",
      "summary": "Deep neural networks (DNNs) are essential for performing advanced tasks on edge or mobile devices, yet their deployment is often hindered by severe resource constraints, including limited memory, energy, and computational power. While uniform quantization provides a straightforward approach to compress model and reduce hardware requirement, it fails to fully leverage the varying robustness across layers, and often lead to accuracy degradation or suboptimal resource usage, particularly at low bit",
      "engagement_score": 0.6521,
      "published_at": "2026-02-25T17:34:14Z",
      "keywords": [
        "cs.LG",
        "cs.AR"
      ],
      "raw_data": {}
    }
  ],
  "total_fetched": 27,
  "timestamp": "2026-02-26T03:16:37.630276+00:00"
}